{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import sys\n",
    "import re\n",
    "lib = __import__(\"ihm_lib\") # provided by [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects to read train and test for each specific task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Path to the Train and Test Data for In Hospital Mortality'\n",
    "inhosmor_reader_train = lib.InHospitalMortalityReader(dataset_dir = path , listfile=path +'listfile.csv')\n",
    "inhosmor_reader_test = lib.InHospitalMortalityReader(dataset_dir = path+'test\\\\', listfile = path +\n",
    "                                                     'test\\\\listfile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Representation of Disease Diagnostic for all the Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihm_train_data = [inhosmor_reader_train.read_example(index) for index in range(inhosmor_reader_train.get_number_of_examples())]\n",
    "ihm_test_data = [inhosmor_reader_test.read_example(index) for index in range(inhosmor_reader_test.get_number_of_examples())]\n",
    "episodes = lib.count_episodes(ihm_train_data)\n",
    "patients_multiple_episodes = episodes[episodes['EPISODE #']>1].index\n",
    "episodes['icu_ids'] = np.ones(episodes.shape[0])\n",
    "all_diagonosis = pd.read_csv(path + 'all_diagnoses.csv') #must be generated after following [1]\n",
    "all_stays = pd.read_csv(path + 'all_stays.csv') #must be generated after following [1]\n",
    "ids = [lib.return_icu_ids(subject,episodes,all_stays) for subject in episodes.index]\n",
    "epi = dict()\n",
    "for i in range(len(list(episodes.index))):\n",
    "    epi[episodes.index[i]] = ids[i]\n",
    "unique_diseases = sorted(all_diagonosis.ICD9_CODE.unique())\n",
    "disease_diagnostics = np.array([lib.binary_representation(np.array(unique_diseases),np.array(lib.extract_diagnosis(i,ihm_train_data,all_diagonosis,epi))) for i in range(len(ihm_train_data))])\n",
    "disease_diagnostics = pd.DataFrame(disease_diagnostics)\n",
    "disease_diagnostics.index = ['-'.join(ihm_train_data[i]['name'].split('_')[:2]) for i in range(len(ihm_train_data))]\n",
    "disease_diagnostics.columns = unique_diseases\n",
    "disease_diagnostics.to_csv(path + 'disease_diagnostics_train.csv')\n",
    "episodes = lib.count_episodes(ihm_test_data)\n",
    "patients_multiple_episodes = episodes[episodes['EPISODE #']>1].index\n",
    "episodes['icu_ids'] = np.ones(episodes.shape[0])\n",
    "all_diagonosis = pd.read_csv(path + 'all_diagnoses.csv') #must be generated after following [1]\n",
    "all_stays = pd.read_csv(path + 'all_stays.csv') #must be generated after following [1]\n",
    "ids = [lib.return_icu_ids(subject,episodes,all_stays) for subject in episodes.index]\n",
    "epi = dict()\n",
    "for i in range(len(list(episodes.index))):\n",
    "    epi[episodes.index[i]] = ids[i]\n",
    "unique_diseases = sorted(all_diagonosis.ICD9_CODE.unique())\n",
    "disease_diagnostics = np.array([lib.binary_representation(np.array(unique_diseases),np.array(lib.extract_diagnosis(i,ihm_test_data,all_diagonosis,epi))) for i in range(len(ihm_test_data))])\n",
    "disease_diagnostics = pd.DataFrame(disease_diagnostics)\n",
    "disease_diagnostics.index = ['-'.join(ihm_test_data[i]['name'].split('_')[:2]) for i in range(len(ihm_test_data))]\n",
    "disease_diagnostics.columns = unique_diseases\n",
    "disease_diagnostics.to_csv(path + 'disease_diagnostics_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Training Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [lib.convert_pandas(index, ihm_train_data) for index in range(len(ihm_train_data))]\n",
    "test = [lib.convert_pandas(index, ihm_test_data) for index in range(len(ihm_test_data))]\n",
    "Size = [train[index].shape[0] for index in range(len(train))]\n",
    "Quantiles = np.quantile(np.array(Size), q=[0.15,0.3,0.45,0.6,0.75,0.8,0.9])\n",
    "interval_length = np.round(( 48 * 60 ) / (95))\n",
    "interval_length = 10\n",
    "Hours = np.round(np.arange(2880,step=10) / (60) , 2)\n",
    "cat_columns = ['Capillary refill rate','Glascow coma scale eye opening', 'Glascow coma scale motor response','Glascow coma scale total','Glascow coma scale verbal response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Unique Values for all Categorical Variables in Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values of Capillary refill rate in entire dataset\n",
      "{'0.0', '1.0'}\n",
      "Unique Values of Glascow coma scale eye opening in entire dataset\n",
      "{'3 To speech', 'Spontaneously', '4 Spontaneously', 'To Pain', '1 No Response', 'None', 'To Speech', '2 To pain'}\n",
      "Unique Values of Glascow coma scale motor response in entire dataset\n",
      "{'2 Abnorm extensn', 'Flex-withdraws', '1 No Response', 'Abnormal extension', '6 Obeys Commands', '4 Flex-withdraws', 'No response', 'Localizes Pain', 'Abnormal Flexion', '3 Abnorm flexion', 'Obeys Commands', '5 Localizes Pain'}\n",
      "Unique Values of Glascow coma scale total in entire dataset\n",
      "{'12', '8', '3', '7', '15', '14', '13', '10', '4', '6', '9', '11', '5'}\n",
      "Unique Values of Glascow coma scale verbal response in entire dataset\n",
      "{'1.0 ET/Trach', 'Incomprehensible sounds', '5 Oriented', '2 Incomp sounds', 'Inappropriate Words', '1 No Response', 'No Response-ETT', 'Confused', '3 Inapprop words', '4 Confused', 'Oriented', 'No Response'}\n"
     ]
    }
   ],
   "source": [
    "crr_train = [lib.extract_string(idx,train,cat_columns[0]) for idx in range(len(train))]\n",
    "crr_test = [lib.extract_string(idx,test,cat_columns[0]) for idx in range(len(test))]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "crr_train = flatten(crr_train)\n",
    "crr_test = flatten(crr_test)\n",
    "print ('Unique Values of Capillary refill rate in entire dataset')\n",
    "print (set(crr_train+crr_test))\n",
    "crr_train = [lib.extract_string(idx,train,cat_columns[1]) for idx in range(len(train))]\n",
    "crr_test = [lib.extract_string(idx,test,cat_columns[1]) for idx in range(len(test))]\n",
    "crr_train = flatten(crr_train)\n",
    "crr_test = flatten(crr_test)\n",
    "print ('Unique Values of Glascow coma scale eye opening in entire dataset')\n",
    "print (set(crr_train+crr_test))\n",
    "crr_train = [lib.extract_string(idx,train,cat_columns[2]) for idx in range(len(train))]\n",
    "crr_test = [lib.extract_string(idx,test,cat_columns[2]) for idx in range(len(test))]\n",
    "crr_train = flatten(crr_train)\n",
    "crr_test = flatten(crr_test)\n",
    "print ('Unique Values of Glascow coma scale motor response in entire dataset')\n",
    "print (set(crr_train+crr_test))\n",
    "crr_train = [lib.extract_string(idx,train,cat_columns[3]) for idx in range(len(train))]\n",
    "crr_test = [lib.extract_string(idx,test,cat_columns[3]) for idx in range(len(test))]\n",
    "crr_train = flatten(crr_train)\n",
    "crr_test = flatten(crr_test)\n",
    "print ('Unique Values of Glascow coma scale total in entire dataset')\n",
    "print (set(crr_train+crr_test))\n",
    "crr_train = [lib.extract_string(idx,train,cat_columns[4]) for idx in range(len(train))]\n",
    "crr_test = [lib.extract_string(idx,test,cat_columns[4]) for idx in range(len(test))]\n",
    "crr_train = flatten(crr_train)\n",
    "crr_test = flatten(crr_test)\n",
    "print ('Unique Values of Glascow coma scale verbal response in entire dataset')\n",
    "print (set(crr_train+crr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorial Variables in Entire Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = ['1.0', '0.0']\n",
    "decoding = ['1.0','0.0']\n",
    "for z in range(len(train)):\n",
    "    train[z].loc[:,cat_columns[0]] = lib.encode_cat(index=z,column=cat_columns[0],data=train,encoding=encoding,decoding=decoding)\n",
    "encoding = ['3 To speech', '4 Spontaneously', 'None', '2 To pain', '1 No Response', 'To Speech', 'To Pain', 'Spontaneously']\n",
    "decoding = ['3','4','0','2','1','5','6','7']\n",
    "for z in range(len(train)):\n",
    "    train[z].loc[:,cat_columns[1]] = lib.encode_cat(index=z,column=cat_columns[1],data=train,encoding=encoding,decoding=decoding)\n",
    "encoding = ['Obeys Commands', 'Localizes Pain', '6 Obeys Commands', '3 Abnorm flexion', 'Flex-withdraws', '1 No Response', 'No response', '2 Abnorm extensn', 'Abnormal Flexion', 'Abnormal extension', '5 Localizes Pain', '4 Flex-withdraws']\n",
    "decoding = list(np.array(np.arange(len(encoding)),dtype=str))\n",
    "for z in range(len(train)):\n",
    "    train[z].loc[:,cat_columns[2]] = lib.encode_cat(index=z,column=cat_columns[2],data=train,encoding=encoding,decoding=decoding)\n",
    "encoding = ['5', '4', '14', '7', '13', '6', '10', '9', '12', '3', '15', '8', '11']\n",
    "decoding = list(np.array(np.arange(len(encoding)),dtype=str))\n",
    "for z in range(len(train)):\n",
    "    train[z].loc[:,cat_columns[3]] = lib.encode_cat(index=z,column=cat_columns[3],data=train,encoding=encoding,decoding=decoding)\n",
    "encoding = ['2 Incomp sounds', 'Oriented', 'Confused', '4 Confused', '1 No Response', 'No Response-ETT', 'Incomprehensible sounds', '3 Inapprop words', '1.0 ET/Trach', 'No Response', 'Inappropriate Words', '5 Oriented']\n",
    "decoding = list(np.array(np.arange(len(encoding)),dtype=str))\n",
    "for z in range(len(train)):\n",
    "    train[z].loc[:,cat_columns[4]] = lib.encode_cat(index=z,column=cat_columns[4],data=train,encoding=encoding,decoding=decoding)\n",
    "encoding = ['1.0', '0.0']\n",
    "decoding = ['1.0','0.0']\n",
    "for z in range(len(test)):\n",
    "    test[z].loc[:,cat_columns[0]] = lib.encode_cat(index=z,column=cat_columns[0],data=test,encoding=encoding,decoding=decoding)\n",
    "encoding = ['3 To speech', '4 Spontaneously', 'None', '2 To pain', '1 No Response', 'To Speech', 'To Pain', 'Spontaneously']\n",
    "decoding = ['3','4','0','2','1','5','6','7']\n",
    "for z in range(len(test)):\n",
    "    test[z].loc[:,cat_columns[1]] = lib.encode_cat(index=z,column=cat_columns[1],data=test,encoding=encoding,decoding=decoding)\n",
    "encoding = ['Obeys Commands', 'Localizes Pain', '6 Obeys Commands', '3 Abnorm flexion', 'Flex-withdraws', '1 No Response', 'No response', '2 Abnorm extensn', 'Abnormal Flexion', 'Abnormal extension', '5 Localizes Pain', '4 Flex-withdraws']\n",
    "decoding = list(np.array(np.arange(len(encoding)),dtype=str))\n",
    "for z in range(len(test)):\n",
    "    test[z].loc[:,cat_columns[2]] = lib.encode_cat(index=z,column=cat_columns[2],data=test,encoding=encoding,decoding=decoding)\n",
    "encoding = ['5', '4', '14', '7', '13', '6', '10', '9', '12', '3', '15', '8', '11']\n",
    "decoding = list(np.array(np.arange(len(encoding)),dtype=str))\n",
    "for z in range(len(test)):\n",
    "    test[z].loc[:,cat_columns[3]] = lib.encode_cat(index=z,column=cat_columns[3],data=test,encoding=encoding,decoding=decoding)\n",
    "encoding = ['2 Incomp sounds', 'Oriented', 'Confused', '4 Confused', '1 No Response', 'No Response-ETT', 'Incomprehensible sounds', '3 Inapprop words', '1.0 ET/Trach', 'No Response', 'Inappropriate Words', '5 Oriented']\n",
    "decoding = list(np.array(np.arange(len(encoding)),dtype=str))\n",
    "for z in range(len(test)):\n",
    "    test[z].loc[:,cat_columns[4]] = lib.encode_cat(index=z,column=cat_columns[4],data=test,encoding=encoding,decoding=decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [lib.fill_missing(idx,train) for idx in range(len(train))]\n",
    "test = [lib.fill_missing(idx,test) for idx in range(len(test))]\n",
    "with open('train_ihm.pickle', 'wb') as handle:\n",
    "    pickle.dump(train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('test_ihm.pickle', 'wb') as handle:\n",
    "    pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
